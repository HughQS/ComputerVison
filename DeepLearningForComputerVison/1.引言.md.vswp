vnote_backup_file_826537664 E:/code/ComputerVison/DeepLearningForComputerVison/1.引言.md
***
# 1.引言
***
&emsp;&emsp;欢迎来到《使用Python进行计算机视觉深度学习---实践卷》！本卷是计算机视觉学习中，完成《使用Python进行计算机视觉深度学习---入门卷》后的下一个学习阶段。<br/>
&emsp;&emsp;此时，你应该对参数学习、神经网络和卷积神经网络（Convolutional Neural Networks, CNNs）的基本原理有了深刻的理解。你也应该对使用Keras库和Python编程语言来训练自己定制的深度学习网络感到相当的顺畅了。<br/>
&emsp;&emsp;《入门卷》的目的是建立起计算机视觉深度学习的知识体系，并引入更高级的算法、概念和行业技巧--这些技术将在本书的三个不同部分介绍。<br/>
&emsp;&emsp;第一部分将重点介绍以某种方式来提高分类准确性的方法。提高分类准确性的一种方法是应用迁移学习方法，如微调或将你的网络视作特征抽取器。<br/>
&emsp;&emsp;我们还将探索集成方法（即训练多个网络并联合这些结果）以及这些方法怎样能给你一个好的分类提升，而仅需很小的额外努力。正则化方法，诸如数据扩充用来产生额外的训练数据--几乎在所有情况下，数据扩充改进了模型的通用性。更高级的优化算法如Adam<sup>[1]</sup>，RMSprop<sup>[2]</sup>，和其它算法也可用于一些数据集来帮助获得更低的损失。在我们回顾了这些技术后，我们将看到应用这些方法的最佳途径，从而确保你使用最少的努力来获得最大的收益。<br/>
&emsp;&emsp;我们继续探讨《实践卷》的第二部分，此部分聚焦在更大的数据集和更奇特的网络结构。到目前为止，我们使用的数据集仅仅适合于我们系统的主内存，但是如果我们的数据集太大而无法一次读入RAM呢？那我们该怎么办呢？当我们使用HDF5时，我们将在第9章解决这个问题。<br/>
&emsp;&emsp;考虑到我们将使用更大的数据集，我们也将讨论更高级的网络结构，如AlexNet、GoogLeNet、Resnet和更深的VGGNet变体。这些网络结构将被用于更具有挑战性的数据集和竞赛，包括Kaggle竞赛：猫狗识别挑战赛<sup>[3]</sup>以及cs231n微型ImageNet挑战赛<sup>[4]</sup>，斯坦福CNN学生也参与了同样的任务。我们将发现，我们使用此技术类型将有能力获得Kaggle猫狗挑战赛排行榜的前25名和cs231n挑战赛的前列。<br/>
&emsp;&emsp;本书的最后部分涵盖了计算机视觉深度学习的应用，包括图像分类、基本目标检测、深度梦想和神经风格、生成对抗网络（GANs）、图像超分辨率。再次，本卷涉及的技术要比《入门卷》更先进，这就是你将自己与深度学习新手区分开来并转变成一个真正的深度学习实践者。为了开始转型为深度学习专家，仅仅需要翻页而已。<br/><br/>
***
# 参考书目
***
[1] Diederik P. Kingma and Jimmy Ba. “Adam: A Method for Stochastic Optimization”. In: CoRR abs/1412.6980 (2014). URL: http://arxiv.org/abs/1412.6980 (cited on pages 11, 85, 86).<br/>
[2] Geoffrey Hinton. Neural Networks for Machine Learning. http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf (cited on pages 11, 85).<br/>
[3] Kaggle Team. Kaggle: Dogs vs. Cats. https://www.kaggle.com/c/dogs-vs-cats (cited on pages 12, 95).<br/>
[4] Andrej Karpathy. Tiny ImageNet Challenge. http://cs231n.stanford.edu/project.html (cited on pages 12, 131, 168)<br/>