# 2.数据增强
&emsp;&emsp;根据Goodfellow等人的观点，正则化是“我们对一个学习算法做的任何修改，目的是去减少它的泛化误差而不是它的训练误差”<sup>[5]</sup>。简言之，正则化是减少我们的测试误差，可能会以增加少量的训练误差为代价。<br/>
&emsp;&emsp;我们已经在《入门卷》的第9章讨论了正则化的不同形式；然而，这些都是正则化的参数化形式，需要我们去更新我们的损失或更新函数。实际上，这儿还有正则化的其它形式：<br/>
&emsp;&emsp;1.修改自身的网络结构。<br/>
&emsp;&emsp;2.增强传递给训练网络的数据集。<br/>
&emsp;&emsp;Dropout是通过修改网络结构实现更好泛化性的一个很好的示例。我们插入一层，在这层随机断开前一层到后一层间的连接节点，确保没有单个节点负责学习怎样去表示一个给定类。<br/>
&emsp;&emsp;在本章的剩余部分，我们将讨论正则化的另一种类型，称为数据增强。这种方法的目的是干扰训练数据，在它们进入网络训练前，轻微地改变它们的外观。最终结果是一个网络始终看到从原始训练数据产生的新的训练数据，一定程度上减少了我们收集更多训练数据的需求（尽管一般来说，收集更多训练数据几乎不会损害你的算法）。<br/>
<br/>
<br/>

---
<div>
<div style="float:left"><a href="./1%20%E5%BC%95%E8%A8%80.md">1 引言</a></div>
<div style="float:right"><a href="./2.1%20%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA.md">2.1 什么是数据增强</a></div>
</div><br/>