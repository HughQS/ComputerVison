## 2.3 有数据增强和无数据增强的训练对比
&emsp;&emsp;在本小节的第一部分中，我们将讨论Flowers-17数据集，（这是一个非常小的数据集，相对于计算机视觉任务的深度学习来说），以及数据增强如何通过生成额外的训练样本来帮助我们人为地增加这个数据集的大小。我们将执行两个实验：<br/>
&emsp;&emsp;1. 在Flowers-17上没有使用数据增强来训练MiniVGGNet。<br/>
&emsp;&emsp;2. 在Flowers-17上使用数据增强来训练MiniVGGNet。<br/>
&emsp;&emsp;我们将发现，应用数据增强显著地减少了过拟合，并允许MiniVGGNet充分地获得更高的分类精度。<br/>

### 2.3.1 Flowers-17数据集
&emsp;&emsp;Flowers-17数据集<sup>[10]</sup>是一个细粒度的分类挑战，我们的任务是识别17种不同种类的花。该图像数据集非常小，总共有1360张图片，每个类仅有80张图片。计算机视觉任务应用深度学习的经验法则是让每个类下有1000-5000个样本，所以此处我们的样本有巨大的不足。<br/>
&emsp;&emsp;我们称Flowers-17为细粒度分类任务，是因为所有类别都非常相似（即花的种类）。实际上，我们可以把每一个类别看作子类别。类别是肯定不同的，但有大量共同的结构（如花瓣、雄蕊、雌蕊等）。对于深度学习的实践者来说，细粒度的分类任务往往是最具挑战性的
，因为它意味着我们的机器学习模型需要学习非常有区别性的特征，去区分那些非常相似的类。这种细粒度的分类任务因为我们有限的训练数据而变得更加困难。<br/>

### 2.3.2 感知方面预处理


```Python

```
&emsp;&emsp;   <br/>


<br/>
<br/>

---

<div align=right><a href="./2.4%20%E6%80%BB%E7%BB%93.md">2.4 总结</a></div>
<br/>